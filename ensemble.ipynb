{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from ultralytics import YOLO\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport csv\nfrom pathlib import Path","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model1 = YOLO(r\"C:\\Users\\Mohan\\Downloads\\last (9).pt\")\nmodel2 = YOLO(r\"C:\\Users\\Mohan\\Downloads\\last (5).pt\")\n\n# 2. Set test image directory and parameters\ntest_data_path = r\"C:\\Users\\Mohan\\Downloads\\competition\\TestImages\\images\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_threshold = 0.01\nstart_idx = 0\nend_idx = 200\ndisplay_images = True\n\n# 3. Create output directories\nos.makedirs(\"output_predictions\", exist_ok=True)\nos.makedirs(\"predictions/labels\", exist_ok=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_files = sorted([\n    f for f in os.listdir(test_data_path) \n    if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n])\n\nif end_idx is None or end_idx > len(image_files):\n    end_idx = len(image_files)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_top_predictions(results, max_predictions=3):\n    \"\"\"Get top predictions from YOLO results\"\"\"\n    if len(results[0].boxes) == 0:\n        return []\n    \n    # Get boxes, confidences, and class IDs\n    boxes = results[0].boxes.xyxy.cpu().numpy()\n    confidences = results[0].boxes.conf.cpu().numpy()\n    class_ids = results[0].boxes.cls.cpu().numpy().astype(int)\n    class_names = results[0].names\n    \n    # Sort by confidence (descending) and take top predictions\n    sorted_indices = np.argsort(confidences)[::-1][:max_predictions]\n    \n    predictions = []\n    for idx in sorted_indices:\n        predictions.append({\n            'box': boxes[idx],\n            'confidence': confidences[idx],\n            'class_id': class_ids[idx],\n            'class_name': class_names[class_ids[idx]]\n        })\n    \n    return predictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def find_common_predictions(pred1, pred2, iou_threshold=0.5):\n    \"\"\"Find common predictions between two models based on IoU and class\"\"\"\n    common_pairs = []\n    used_pred2_indices = set()\n    \n    for i, p1 in enumerate(pred1):\n        for j, p2 in enumerate(pred2):\n            if j in used_pred2_indices:\n                continue\n                \n            # Check if same class\n            if p1['class_id'] == p2['class_id']:\n                # Calculate IoU\n                iou = calculate_iou(p1['box'], p2['box'])\n                if iou > iou_threshold:\n                    common_pairs.append((i, j, p1, p2))\n                    used_pred2_indices.add(j)\n                    break\n    \n    return common_pairs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_iou(box1, box2):\n    \"\"\"Calculate Intersection over Union (IoU) of two bounding boxes\"\"\"\n    x1_min, y1_min, x1_max, y1_max = box1\n    x2_min, y2_min, x2_max, y2_max = box2\n    \n    # Calculate intersection\n    inter_x_min = max(x1_min, x2_min)\n    inter_y_min = max(y1_min, y2_min)\n    inter_x_max = min(x1_max, x2_max)\n    inter_y_max = min(y1_max, y2_max)\n    \n    if inter_x_max <= inter_x_min or inter_y_max <= inter_y_min:\n        return 0.0\n    \n    inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)\n    \n    # Calculate union\n    area1 = (x1_max - x1_min) * (y1_max - y1_min)\n    area2 = (x2_max - x2_min) * (y2_max - y2_min)\n    union_area = area1 + area2 - inter_area\n    \n    return inter_area / union_area if union_area > 0 else 0.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def convert_to_yolo_format(predictions, img_width, img_height):\n    \"\"\"Convert predictions to YOLO format\"\"\"\n    yolo_lines = []\n    \n    for pred in predictions:\n        x1, y1, x2, y2 = pred['box']\n        conf = pred['confidence']\n        cls_id = pred['class_id']\n        \n        # Convert to YOLO format\n        x_center = ((x1 + x2) / 2) / img_width\n        y_center = ((y1 + y2) / 2) / img_height\n        width = (x2 - x1) / img_width\n        height = (y2 - y1) / img_height\n        \n        yolo_lines.append(f\"{int(cls_id)} {conf:.6f} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n    \n    return yolo_lines","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Run predictions and compare results\nfor idx in range(start_idx, end_idx):\n    image_path = os.path.join(test_data_path, image_files[idx])\n    \n    print(f\"\\nüì∏ Processing: {image_files[idx]}\")\n    \n    # Get predictions from both models\n    results1 = model1.predict(source=image_path, conf=conf_threshold, save=False, verbose=False)\n    results2 = model2.predict(source=image_path, conf=conf_threshold, save=False, verbose=False)\n    \n    # Get image dimensions\n    img_height, img_width = results1[0].orig_shape\n    \n    # Get top 3 predictions from each model\n    pred1 = get_top_predictions(results1, max_predictions=3)\n    pred2 = get_top_predictions(results2, max_predictions=3)\n    \n    print(f\"Model 1 predictions: {len(pred1)}\")\n    print(f\"Model 2 predictions: {len(pred2)}\")\n    \n    # Find common predictions\n    common_pairs = find_common_predictions(pred1, pred2)\n    \n    # Get common predictions (use higher confidence from both models)\n    common_predictions = []\n    for pair in common_pairs:\n        pred1_common = pair[2]\n        pred2_common = pair[3]\n        \n        # Use prediction with higher confidence\n        if pred1_common['confidence'] >= pred2_common['confidence']:\n            common_predictions.append(pred1_common)\n        else:\n            common_predictions.append(pred2_common)\n    \n    # Get unique predictions (not in common)\n    used_pred1_indices = {pair[0] for pair in common_pairs}\n    used_pred2_indices = {pair[1] for pair in common_pairs}\n    \n    unique_pred1 = [pred1[i] for i in range(len(pred1)) if i not in used_pred1_indices]\n    unique_pred2 = [pred2[i] for i in range(len(pred2)) if i not in used_pred2_indices]\n    \n    # Combine all predictions for submission\n    all_combined_predictions = common_predictions + unique_pred1 + unique_pred2\n    \n    # Sort by confidence and take top 3\n    all_combined_predictions.sort(key=lambda x: x['confidence'], reverse=True)\n    final_predictions = all_combined_predictions[:3]\n    \n    print(f\"Common predictions: {len(common_predictions)}\")\n    print(f\"Unique to Model 1: {len(unique_pred1)}\")\n    print(f\"Unique to Model 2: {len(unique_pred2)}\")\n    print(f\"Final combined predictions: {len(final_predictions)}\")\n    \n    # Convert to YOLO format and save\n    base_name = os.path.splitext(image_files[idx])[0]\n    output_txt = os.path.join(\"predictions/labels\", f\"{base_name}.txt\")\n    \n    yolo_lines = convert_to_yolo_format(final_predictions, img_width, img_height)\n    \n    with open(output_txt, \"w\") as f:\n        for line in yolo_lines:\n            f.write(line + \"\\n\")\n    \n    # Store for submission CSV\n    pred_string = \" \".join(yolo_lines) if yolo_lines else \"no boxes\"\n    all_predictions.append({\n        \"image_id\": base_name,\n        \"prediction_string\": pred_string\n    })\n    \n    if display_images:\n        # Load original image\n        combined_image = cv2.imread(image_path)\n        combined_image_rgb = cv2.cvtColor(combined_image, cv2.COLOR_BGR2RGB)\n        \n        # Draw common predictions in RED\n        for pred in common_predictions:\n            x1, y1, x2, y2 = pred['box'].astype(int)\n            cv2.rectangle(combined_image_rgb, (x1, y1), (x2, y2), (255, 0, 0), 3)  # Red for common\n            label = f\"COMMON: {pred['class_name']} {pred['confidence']:.2f}\"\n            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n            \n            # Background for text\n            cv2.rectangle(combined_image_rgb, (x1, y1 - label_size[1] - 10), \n                         (x1 + label_size[0], y1), (255, 0, 0), -1)\n            cv2.putText(combined_image_rgb, label, (x1, y1 - 5), \n                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n        \n        # Draw unique predictions from Model 1 in GREEN\n        for pred in unique_pred1:\n            x1, y1, x2, y2 = pred['box'].astype(int)\n            cv2.rectangle(combined_image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green for Model 1 unique\n            label = f\"M1: {pred['class_name']} {pred['confidence']:.2f}\"\n            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n            \n            # Background for text\n            cv2.rectangle(combined_image_rgb, (x1, y1 - label_size[1] - 10), \n                         (x1 + label_size[0], y1), (0, 255, 0), -1)\n            cv2.putText(combined_image_rgb, label, (x1, y1 - 5), \n                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n        \n        # Draw unique predictions from Model 2 in BLUE\n        for pred in unique_pred2:\n            x1, y1, x2, y2 = pred['box'].astype(int)\n            cv2.rectangle(combined_image_rgb, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Blue for Model 2 unique\n            label = f\"M2: {pred['class_name']} {pred['confidence']:.2f}\"\n            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n            \n            # Background for text\n            cv2.rectangle(combined_image_rgb, (x1, y1 - label_size[1] - 10), \n                         (x1 + label_size[0], y1), (0, 0, 255), -1)\n            cv2.putText(combined_image_rgb, label, (x1, y1 - 5), \n                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n        \n        # Display single combined image\n        plt.figure(figsize=(12, 8))\n        plt.imshow(combined_image_rgb)\n        plt.axis('off')\n        \n        # Create title with counts\n        title = f\"Model Comparison: {image_files[idx]}\\n\"\n        title += f\"üî¥ Common: {len(common_predictions)} | üü¢ Model1 Only: {len(unique_pred1)} | üîµ Model2 Only: {len(unique_pred2)}\"\n        title += f\"\\nüìÑ Final Submission: {len(final_predictions)} predictions\"\n        plt.title(title, fontsize=14, pad=20)\n        plt.tight_layout()\n        plt.show()\n    \n    # Save single combined result\n    combined_save_image = cv2.imread(image_path)\n    combined_save_image_rgb = cv2.cvtColor(combined_save_image, cv2.COLOR_BGR2RGB)\n    \n    # Draw all predictions on save image\n    for pred in common_predictions:\n        x1, y1, x2, y2 = pred['box'].astype(int)\n        cv2.rectangle(combined_save_image_rgb, (x1, y1), (x2, y2), (255, 0, 0), 3)  # Red for common\n        label = f\"COMMON: {pred['class_name']} {pred['confidence']:.2f}\"\n        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n        cv2.rectangle(combined_save_image_rgb, (x1, y1 - label_size[1] - 10), \n                     (x1 + label_size[0], y1), (255, 0, 0), -1)\n        cv2.putText(combined_save_image_rgb, label, (x1, y1 - 5), \n                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n    \n    for pred in unique_pred1:\n        x1, y1, x2, y2 = pred['box'].astype(int)\n        cv2.rectangle(combined_save_image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green for Model 1\n        label = f\"M1: {pred['class_name']} {pred['confidence']:.2f}\"\n        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n        cv2.rectangle(combined_save_image_rgb, (x1, y1 - label_size[1] - 10), \n                     (x1 + label_size[0], y1), (0, 255, 0), -1)\n        cv2.putText(combined_save_image_rgb, label, (x1, y1 - 5), \n                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n    \n    for pred in unique_pred2:\n        x1, y1, x2, y2 = pred['box'].astype(int)\n        cv2.rectangle(combined_save_image_rgb, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Blue for Model 2\n        label = f\"M2: {pred['class_name']} {pred['confidence']:.2f}\"\n        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n        cv2.rectangle(combined_save_image_rgb, (x1, y1 - label_size[1] - 10), \n                     (x1 + label_size[0], y1), (0, 0, 255), -1)\n        cv2.putText(combined_save_image_rgb, label, (x1, y1 - 5), \n                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n    \n    # Save combined image\n    combined_pil = Image.fromarray(combined_save_image_rgb)\n    combined_path = os.path.join(\"output_predictions\", f\"combined_{base_name}.jpg\")\n    combined_pil.save(combined_path)\n    print(f\"‚úÖ Saved combined: {combined_path}\")\n\nprint(f\"\\n[‚úÖ] All predictions saved in: predictions/labels\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create submission CSV\ndef create_submission_csv(\n    predictions_list,\n    output_csv: str = \"submission.csv\",\n    test_images_folder: str = None\n):\n    \"\"\"Create submission CSV from predictions list\"\"\"\n    \n    # Convert predictions list to DataFrame\n    submission_df = pd.DataFrame(predictions_list)\n    \n    # If test images folder is provided, check for missing images\n    if test_images_folder:\n        test_images_path = Path(test_images_folder)\n        allowed_extensions = (\".jpg\", \".png\", \".jpeg\")\n        test_images = {p.stem for p in test_images_path.glob(\"*\") if p.suffix.lower() in allowed_extensions}\n        \n        predicted_images = set(submission_df['image_id'].tolist())\n        missing_images = test_images - predicted_images\n        \n        # Add missing images with \"no boxes\"\n        for image_id in missing_images:\n            submission_df = pd.concat([\n                submission_df,\n                pd.DataFrame([{\"image_id\": image_id, \"prediction_string\": \"no boxes\"}])\n            ], ignore_index=True)\n    \n    # Sort by image_id for consistency\n    submission_df = submission_df.sort_values('image_id').reset_index(drop=True)\n    \n    # Save to CSV\n    submission_df.to_csv(output_csv, index=False, quoting=csv.QUOTE_MINIMAL)\n    print(f\"[notice] ‚úÖ Submission saved to {output_csv}\")\n    print(f\"[notice] üìä Total submissions: {len(submission_df)}\")\n    \n    return submission_df\n\n# Create submission file\nsubmission_df = create_submission_csv(\n    all_predictions,\n    output_csv=\"dual_model_submission.csv\",\n    test_images_folder=test_data_path\n)\n\nprint(\"\\nüéâ Dual model submission completed!\")\nprint(f\"üìÅ Label files: predictions/labels/\")\nprint(f\"üìÑ Submission CSV: dual_model_submission.csv\")\nprint(f\"üñºÔ∏è Visualization images: output_predictions/\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}