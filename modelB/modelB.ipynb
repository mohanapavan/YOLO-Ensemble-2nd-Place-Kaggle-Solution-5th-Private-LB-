{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":99173,"databundleVersionId":11843845,"sourceType":"competition"},{"sourceId":104781,"databundleVersionId":12610790,"sourceType":"competition"},{"sourceId":12200122,"sourceType":"datasetVersion","datasetId":7642535}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics\nimport pandas as pd\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ultralytics import YOLO\nfrom pathlib import Path\nimport csv\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:42:18.209456Z","iopub.execute_input":"2025-06-20T04:42:18.209649Z","iopub.status.idle":"2025-06-20T04:43:36.811563Z","shell.execute_reply.started":"2025-06-20T04:42:18.209631Z","shell.execute_reply":"2025-06-20T04:43:36.810722Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wget https://storage.googleapis.com/duality-public-share/Hackathons/kaggle2/coolLighting.zip\n!wget https://storage.googleapis.com/duality-public-share/Hackathons/kaggle2/cameraDistance.zip\n!wget https://storage.googleapis.com/duality-public-share/Hackathons/kaggle2/furniture.zip\n!wget https://storage.googleapis.com/duality-public-share/Hackathons/kaggle2/plants.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:43:36.815240Z","iopub.execute_input":"2025-06-20T04:43:36.815482Z","iopub.status.idle":"2025-06-20T04:44:01.929218Z","shell.execute_reply.started":"2025-06-20T04:43:36.815458Z","shell.execute_reply":"2025-06-20T04:44:01.928430Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!unzip -q coolLighting.zip -d coolLighting\n!unzip -q cameraDistance.zip -d cameraDistance\n!unzip -q furniture.zip -d furniture\n!unzip -q plants.zip -d plants\nprint(\"âœ… All files extracted successfully.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_yaml = \"\"\"\npath: /kaggle/input/synthetic-2-real-object-detection-challenge-2/Synthetic to Real Object Detection Challenge 2\n\ntrain:\n  - /kaggle/input/synthetic-2-real-object-detection-challenge-2/Synthetic to Real Object Detection Challenge 2/train/images\n  - /kaggle/working/cameraDistance/cameraDistance/images\n  - /kaggle/working/coolLighting/coolLighting/images\n  - /kaggle/working/furniture/furniture/images\n  - /kaggle/working/plants/plants/images\n  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/clutter/train/images\n  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/couch_far_10/train/images\n  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/far_10_half_clutter/train/images\n  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/film_grain_10_half_clutter/train/images\n  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/large_plant_10/train/images\n  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/no_clutter_10/train/images\n  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/table_close_10/train/images\n  - /kaggle/input/falcon-soup-cans/outputallcarpet/Output/2025-06-11-23-00-26/train/images\n  - /kaggle/input/falcon-soup-cans/outputallcouch/Output/2025-06-08-20-02-03/train/images\n  - /kaggle/input/falcon-soup-cans/outputallfridge/Output/2025-06-11-22-20-13/train/images\n  - /kaggle/input/falcon-soup-cans/outputallplant/Output/2025-06-11-22-36-54/train/images\n  - /kaggle/input/falcon-soup-cans/outputalltable/Output/2025-06-08-13-07-03/train/images\n  - /kaggle/input/falcon-soup-cans/outputalltv/Output/2025-06-11-23-12-59/train/images\n  - /kaggle/input/falcon-soup-cans/outputcarpet2/Output/2025-06-14-14-56-25/train/images\n  - /kaggle/input/falcon-soup-cans/outputcarpet3/Output/2025-06-14-15-16-52/train/images\n  - /kaggle/input/falcon-soup-cans/outputcarpet4/Output/2025-06-14-15-38-01/train/images\n  - /kaggle/input/falcon-soup-cans/outputcarpet5/Output/2025-06-14-15-51-52/train/images\n  - /kaggle/input/falcon-soup-cans/outputcouch2/Output/2025-06-14-18-16-50/train/images\n  - /kaggle/input/falcon-soup-cans/outputcouch3/Output/2025-06-14-18-36-09/train/images\n  - /kaggle/input/falcon-soup-cans/outputcouch4/Output/2025-06-14-19-02-23/train/images\n  - /kaggle/input/falcon-soup-cans/outputcouch5/Output/2025-06-14-19-38-30/train/images\n  - /kaggle/input/falcon-soup-cans/outputfridge2/Output/2025-06-14-20-29-36/train/images\n  - /kaggle/input/falcon-soup-cans/outputfridge3/Output/2025-06-14-21-11-53/train/images\n  - /kaggle/input/falcon-soup-cans/outputfridge4/Output/2025-06-14-21-41-28/train/images\n  - /kaggle/input/falcon-soup-cans/outputfridge5/Output/2025-06-14-22-07-39/train/images\n  - /kaggle/input/falcon-soup-cans/outputtable2/Output/2025-06-14-12-36-22/train/images\n  - /kaggle/input/falcon-soup-cans/outputtable3/Output/2025-06-14-13-28-58/train/images\n  - /kaggle/input/falcon-soup-cans/outputtable4/Output/2025-06-14-13-46-12/train/images\n  - /kaggle/input/falcon-soup-cans/outputtable5/Output/2025-06-14-14-23-33/train/images\n  - /kaggle/input/falcon-soup-cans/outputtv2/Output/2025-06-15-19-57-01/train/images\n  - /kaggle/input/falcon-soup-cans/outputtv3/Output/2025-06-15-20-13-50/train/images\n  - /kaggle/input/falcon-soup-cans/outputtv4/Output/2025-06-15-20-44-05/train/images\n  - /kaggle/input/falcon-soup-cans/outputtv5/Output/2025-06-15-20-59-03/train/images\n  - /kaggle/input/falcon-soup-cans/topfridge1/Output/2025-06-17-18-29-33/train/images\n  - /kaggle/input/falcon-soup-cans/topfridge2/Output/2025-06-17-20-41-52/train/images\n  - /kaggle/input/falcon-soup-cans/topfridge3/Output/2025-06-17-21-02-37/train/images\n  - /kaggle/input/falcon-soup-cans/topfridge4/Output/2025-06-17-21-24-25/train/images\n  - /kaggle/input/falcon-soup-cans/topfridge5/Output/2025-06-17-21-57-17/train/images\n  \nval: \n  - /kaggle/input/synthetic-2-real-object-detection-challenge-2/Synthetic to Real Object Detection Challenge 2/val/images\n  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/clutter/val/images\n  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/couch_far_10/val/images\n  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/far_10_half_clutter/val/images\n  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/film_grain_10_half_clutter/val/images\n  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/large_plant_10/val/images\n  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/no_clutter_10/val/images\n  - /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/table_close_10/val/images\n  - /kaggle/input/falcon-soup-cans/outputallcarpet/Output/2025-06-11-23-00-26/val/images\n  - /kaggle/input/falcon-soup-cans/outputallcouch/Output/2025-06-08-20-02-03/val/images\n  - /kaggle/input/falcon-soup-cans/outputallfridge/Output/2025-06-11-22-20-13/val/images\n  - /kaggle/input/falcon-soup-cans/outputallplant/Output/2025-06-11-22-36-54/val/images\n  - /kaggle/input/falcon-soup-cans/outputalltable/Output/2025-06-08-13-07-03/val/images\n  - /kaggle/input/falcon-soup-cans/outputalltv/Output/2025-06-11-23-12-59/val/images\n  - /kaggle/input/falcon-soup-cans/outputcarpet2/Output/2025-06-14-14-56-25/val/images\n  - /kaggle/input/falcon-soup-cans/outputcarpet3/Output/2025-06-14-15-16-52/val/images\n  - /kaggle/input/falcon-soup-cans/outputcarpet4/Output/2025-06-14-15-38-01/val/images\n  - /kaggle/input/falcon-soup-cans/outputcarpet5/Output/2025-06-14-15-51-52/val/images\n  - /kaggle/input/falcon-soup-cans/outputcouch2/Output/2025-06-14-18-16-50/val/images\n  - /kaggle/input/falcon-soup-cans/outputcouch3/Output/2025-06-14-18-36-09/val/images\n  - /kaggle/input/falcon-soup-cans/outputcouch4/Output/2025-06-14-19-02-23/val/images\n  - /kaggle/input/falcon-soup-cans/outputcouch5/Output/2025-06-14-19-38-30/val/images\n  - /kaggle/input/falcon-soup-cans/outputfridge2/Output/2025-06-14-20-29-36/val/images\n  - /kaggle/input/falcon-soup-cans/outputfridge3/Output/2025-06-14-21-11-53/val/images\n  - /kaggle/input/falcon-soup-cans/outputfridge4/Output/2025-06-14-21-41-28/val/images\n  - /kaggle/input/falcon-soup-cans/outputfridge5/Output/2025-06-14-22-07-39/val/images\n  - /kaggle/input/falcon-soup-cans/outputtable2/Output/2025-06-14-12-36-22/val/images\n  - /kaggle/input/falcon-soup-cans/outputtable3/Output/2025-06-14-13-28-58/val/images\n  - /kaggle/input/falcon-soup-cans/outputtable4/Output/2025-06-14-13-46-12/val/images\n  - /kaggle/input/falcon-soup-cans/outputtable5/Output/2025-06-14-14-23-33/val/images\n  - /kaggle/input/falcon-soup-cans/outputtv2/Output/2025-06-15-19-57-01/val/images\n  - /kaggle/input/falcon-soup-cans/outputtv3/Output/2025-06-15-20-13-50/val/images\n  - /kaggle/input/falcon-soup-cans/outputtv4/Output/2025-06-15-20-44-05/val/images\n  - /kaggle/input/falcon-soup-cans/outputtv5/Output/2025-06-15-20-59-03/val/images\n  - /kaggle/input/falcon-soup-cans/topfridge1/Output/2025-06-17-18-29-33/val/images\n  - /kaggle/input/falcon-soup-cans/topfridge2/Output/2025-06-17-20-41-52/val/images\n  - /kaggle/input/falcon-soup-cans/topfridge3/Output/2025-06-17-21-02-37/val/images\n  - /kaggle/input/falcon-soup-cans/topfridge4/Output/2025-06-17-21-24-25/val/images\n  - /kaggle/input/falcon-soup-cans/topfridge5/Output/2025-06-17-21-57-17/val/images\n  \ntest: /kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/TestImages/images\n\nnc: 1\nnames: ['soup can']\n\"\"\"\n\n# DosyayÄ± kaydet\nwith open('data.yaml', 'w') as file:\n    file.write(data_yaml)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\n\nmodel = YOLO(\"yolov8s.pt\")\n\nresults = model.train(\n    data=\"data.yaml\",\n    epochs=50,                  # Increased for convergence (early stopping will handle overfitting)\n    imgsz=1280,                  # High resolution for small objects\n    batch=16,         # Early stopping if no improvement\n    cos_lr=True,                # Cosine learning rate scheduler\n    dropout=0.3,                # Regularization to prevent overfitting\n    mosaic=0.3,                 # More aggressive augmentation (50% chance)\n    lr0=0.001,\n    lrf=0.001,        # Initial LR (higher for SGD)\n    optimizer=\"SGD\",          # AdamW > SGD for adaptive learning rates\n    momentum=0.937,\n    weight_decay=0.0005,\n    single_cls=True, \n    plots=True,\n    hsv_h=0.0,\n    cache=True,\n    erasing=0.3,\n    device=\"0\",                 # Use GPU 0\n    workers=8,\n    flipud=0.4,\n    close_mosaic=10,\n    fliplr=0.2,\n    cutmix=0.3,\n    save_period=10\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the best model after training\nmodel = YOLO('/kaggle/working/runs/detect/train/weights/last.pt')\n\n# Test-Time Augmentation (TTA) for improved predictions\ntest_images_path = \"/kaggle/input/multi-instance-object-detection-challenge/Starter_Dataset/TestImages/images\"\noutput_dir = \"/kaggle/working/predictions/labels\"\n\nos.makedirs(output_dir, exist_ok=True)\n\nfor img_path in Path(test_images_path).glob(\"*\"):\n    if img_path.suffix.lower() not in ['.png', '.jpg', '.jpeg']:\n        continue\n\n    # Use TTA during prediction\n    results = model.predict(img_path, conf=0.05, augment=True)  # Enable TTA\n\n    output_txt = Path(output_dir) / f\"{img_path.stem}.txt\"\n\n    with open(output_txt, \"w\") as f:\n        for result in results:\n            img_height, img_width = result.orig_shape\n            for box in result.boxes.data:\n                x1, y1, x2, y2, confidence, cls_id = box.tolist()\n\n                x_center = ((x1 + x2) / 2) / img_width\n                y_center = ((y1 + y2) / 2) / img_height\n                width = (x2 - x1) / img_width\n                height = (y2 - y1) / img_height\n\n                f.write(f\"0 {confidence:.6f} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n\nprint(f\"[notice] âœ… Predictions saved: {output_dir}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert predictions to CSV\ndef predictions_to_csv(\n    preds_folder: str = \"/kaggle/working/predictions/labels\", \n    output_csv: str = \"/kaggle/working/submissionv.csv\", \n    test_images_folder: str = \"/kaggle/input/synthetic-2-real-object-detection-challenge/Synthetic to Real Object Detection Challenge/data/test/images\",\n    allowed_extensions: tuple = (\".jpg\", \".png\", \".jpeg\")\n):\n    preds_path = Path(preds_folder)\n    test_images_path = Path(test_images_folder)\n\n    test_images = {p.stem for p in test_images_path.glob(\"*\") if p.suffix.lower() in allowed_extensions}\n\n    predictions = []\n    predicted_images = set()\n\n    for txt_file in preds_path.glob(\"*.txt\"):\n        image_id = txt_file.stem\n        predicted_images.add(image_id)\n\n        with open(txt_file, \"r\") as f:\n            valid_lines = [line.strip() for line in f if len(line.strip().split()) == 6]\n\n        pred_str = \" \".join(valid_lines) if valid_lines else \"no boxes\"\n        predictions.append({\"image_id\": image_id, \"prediction_string\": pred_str})\n\n    missing_images = test_images - predicted_images\n    for image_id in missing_images:\n        predictions.append({\"image_id\": image_id, \"prediction_string\": \"no boxes\"})\n\n    submission_df = pd.DataFrame(predictions)\n    submission_df.to_csv(output_csv, index=False, quoting=csv.QUOTE_MINIMAL)\n\n    print(f\"[notice] âœ… Submission saved to {output_csv}\")\n\npredictions_to_csv()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}